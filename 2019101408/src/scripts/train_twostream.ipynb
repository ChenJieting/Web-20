{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "posA = \"dataset/celeA\"\n",
    "posB = \"dataset/flickr\"\n",
    "negA = \"dataset/stylegan\"\n",
    "negB = \"dataset/fake1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 400, 400, 3200, 400, 400)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = [os.path.join(posA,filename)for filename in os.listdir(posA)][:800] + \\\n",
    "            [os.path.join(posB,filename)for filename in os.listdir(posB)][:800] + \\\n",
    "            [os.path.join(negA,filename)for filename in os.listdir(negA)][:800] + \\\n",
    "            [os.path.join(negB,filename)for filename in os.listdir(negB)][:800]\n",
    "trainlabel = [1]*1600 + [0]*1600\n",
    "\n",
    "validdata = [os.path.join(posA,filename)for filename in os.listdir(posA)][800:900] + \\\n",
    "            [os.path.join(posB,filename)for filename in os.listdir(posB)][800:900] + \\\n",
    "            [os.path.join(negA,filename)for filename in os.listdir(negA)][800:900] + \\\n",
    "            [os.path.join(negB,filename)for filename in os.listdir(negB)][800:900]\n",
    "validlabel = [1]*200 + [0]*200\n",
    "\n",
    "testdata  = [os.path.join(posA,filename)for filename in os.listdir(posA)][900:] + \\\n",
    "            [os.path.join(posB,filename)for filename in os.listdir(posB)][900:] + \\\n",
    "            [os.path.join(negA,filename)for filename in os.listdir(negA)][900:] + \\\n",
    "            [os.path.join(negB,filename)for filename in os.listdir(negB)][900:]\n",
    "testlabel = [1]*200 + [0]*200\n",
    "\n",
    "len(traindata),len(validdata),len(testdata),len(trainlabel),len(validlabel),len(testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRMConv(img):\n",
    "    filter1 = np.array([[0,0,0,0,0],\n",
    "                        [0,-1,2,-1,0],\n",
    "                        [0,2,-4,2,0],\n",
    "                        [0,-1,2,-1,0],\n",
    "                        [0,0,0,0,0]]) /4\n",
    "    filter2 = np.array([[-1,2,-2,2,-1],\n",
    "                        [2,-6,8,-6,2],\n",
    "                        [-2,8,-12,8,-2],\n",
    "                        [2,-6,8,-6,2],\n",
    "                        [-1,2,-2,2,-1]]) / 12\n",
    "    filter3 = np.array([[0,0,0,0,0],\n",
    "                        [0,0,0,0,0],\n",
    "                        [0,1,-2,1,0],\n",
    "                        [0,0,0,0,0],\n",
    "                        [0,0,0,0,0]]) / 2\n",
    "    dst1 = np.sum(cv2.filter2D(img, cv2.CV_32F, filter1),axis=2)\n",
    "    dst2 = np.sum(cv2.filter2D(img, cv2.CV_32F, filter2),axis=2)\n",
    "    dst3 = np.sum(cv2.filter2D(img, cv2.CV_32F, filter3),axis=2)\n",
    "    \n",
    "    #noise = np.concatenate((dst1,dst2,dst3),axis=2)\n",
    "    noise = np.dstack((dst1,dst2,dst3))\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfakeData(Dataset):\n",
    "    def __init__(self, pathList, labelList, transform=None):\n",
    "        self.pathList = pathList\n",
    "        self.labelList = labelList\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pathList)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        img = cv2.imread(self.pathList[index])\n",
    "        raw_img = img\n",
    "        img = SRMConv(img)\n",
    "        label = self.labelList[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            raw_img = self.transform(raw_img)\n",
    "            \n",
    "        return (raw_img, img), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "traindataset = DeepfakeData(traindata, trainlabel, transform)\n",
    "validdataset = DeepfakeData(validdata, validlabel, transform)\n",
    "testdataset = DeepfakeData(testdata, testlabel, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 4\n",
    "trainloader = DataLoader(traindataset, batch_size=batchsize, shuffle=True, num_workers=4)\n",
    "validloader = DataLoader(validdataset)\n",
    "testloader = DataLoader(testdataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet_cam\n",
    "class twoStreamCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(twoStreamCNN,self).__init__()\n",
    "        self.model1 = resnet_cam.resnet18(pretrained=True)\n",
    "        self.model1.fc = torch.nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "        self.model2 = resnet_cam.resnet18(pretrained=True)\n",
    "        self.model2.fc = torch.nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "        self.fc = torch.nn.Linear(1024,2)\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        _,x1 = self.model1(x1)\n",
    "        _,x2 = self.model2(x2)\n",
    "        x = torch.cat((x1,x2),1)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x.size()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = twoStreamCNN()\n",
    "#net.cuda()\n",
    "net.to(device)\n",
    "epoch_max = 50\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wws/environment/python3.5.2/local/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss:0.9625416994094849 iter:0\n",
      "Epoch:0 Loss:0.6921111941337585 iter:400\n",
      "Epoch:0 Loss:0.6977041959762573 iter:800\n",
      "Epoch:0 Loss:0.45439285039901733 iter:1200\n",
      "Epoch:0 Loss:0.4538036584854126 iter:1600\n",
      "Epoch:0 Loss:0.37040990591049194 iter:2000\n",
      "Epoch:0 Loss:0.4453166127204895 iter:2400\n",
      "Epoch:0 Loss:0.43949562311172485 iter:2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wws/environment/python3.5.2/local/lib/python3.5/site-packages/ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "EVALUATION\n",
      "Epoch:0 Loss:0.21836665272712708 acc:0.9625\n",
      "##########################################################################\n",
      "Epoch:1 Loss:0.19982028007507324 iter:0\n",
      "Epoch:1 Loss:0.31860360503196716 iter:400\n",
      "Epoch:1 Loss:0.2967146039009094 iter:800\n",
      "Epoch:1 Loss:0.31556326150894165 iter:1200\n",
      "Epoch:1 Loss:0.25907251238822937 iter:1600\n",
      "Epoch:1 Loss:0.2776937484741211 iter:2000\n",
      "Epoch:1 Loss:0.26153188943862915 iter:2400\n",
      "Epoch:1 Loss:0.23635952174663544 iter:2800\n",
      "!\n",
      "EVALUATION\n",
      "Epoch:1 Loss:0.10613177716732025 acc:0.9725\n",
      "##########################################################################\n",
      "Epoch:2 Loss:0.04279494285583496 iter:0\n",
      "Epoch:2 Loss:0.2767707407474518 iter:400\n",
      "Epoch:2 Loss:0.2682432234287262 iter:800\n",
      "Epoch:2 Loss:0.22415092587471008 iter:1200\n",
      "Epoch:2 Loss:0.2369365692138672 iter:1600\n",
      "Epoch:2 Loss:0.18271483480930328 iter:2000\n",
      "Epoch:2 Loss:0.22947832942008972 iter:2400\n",
      "Epoch:2 Loss:0.19693158566951752 iter:2800\n",
      "!\n",
      "EVALUATION\n",
      "Epoch:2 Loss:0.09857143461704254 acc:0.975\n",
      "##########################################################################\n",
      "Epoch:3 Loss:0.026452302932739258 iter:0\n",
      "Epoch:3 Loss:0.15538500249385834 iter:400\n",
      "Epoch:3 Loss:0.2506093680858612 iter:800\n",
      "Epoch:3 Loss:0.18826957046985626 iter:1200\n",
      "Epoch:3 Loss:0.17337778210639954 iter:1600\n",
      "Epoch:3 Loss:0.1696237176656723 iter:2000\n",
      "Epoch:3 Loss:0.17260530591011047 iter:2400\n",
      "Epoch:3 Loss:0.2161979228258133 iter:2800\n",
      "!\n",
      "EVALUATION\n",
      "Epoch:3 Loss:0.1001831665635109 acc:0.9825\n",
      "##########################################################################\n",
      "Epoch:4 Loss:0.018703460693359375 iter:0\n",
      "Epoch:4 Loss:0.22026465833187103 iter:400\n",
      "Epoch:4 Loss:0.1447189301252365 iter:800\n",
      "Epoch:4 Loss:0.1370069682598114 iter:1200\n",
      "Epoch:4 Loss:0.18875159323215485 iter:1600\n",
      "Epoch:4 Loss:0.17431403696537018 iter:2000\n",
      "Epoch:4 Loss:0.14090654253959656 iter:2400\n",
      "Epoch:4 Loss:0.135818749666214 iter:2800\n",
      "EVALUATION\n",
      "Epoch:4 Loss:0.07308173179626465 acc:0.9825\n",
      "##########################################################################\n",
      "Epoch:5 Loss:0.6921169757843018 iter:0\n",
      "Epoch:5 Loss:0.10173723846673965 iter:400\n",
      "Epoch:5 Loss:0.15308699011802673 iter:800\n",
      "Epoch:5 Loss:0.10243938118219376 iter:1200\n",
      "Epoch:5 Loss:0.09911279380321503 iter:1600\n",
      "Epoch:5 Loss:0.13966332376003265 iter:2000\n",
      "Epoch:5 Loss:0.17695777118206024 iter:2400\n",
      "Epoch:5 Loss:0.12173378467559814 iter:2800\n",
      "!\n",
      "EVALUATION\n",
      "Epoch:5 Loss:0.03614437207579613 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:6 Loss:0.10936260223388672 iter:0\n",
      "Epoch:6 Loss:0.14120492339134216 iter:400\n",
      "Epoch:6 Loss:0.11204268038272858 iter:800\n",
      "Epoch:6 Loss:0.11584796756505966 iter:1200\n",
      "Epoch:6 Loss:0.13433358073234558 iter:1600\n",
      "Epoch:6 Loss:0.143843412399292 iter:2000\n",
      "Epoch:6 Loss:0.09220652282238007 iter:2400\n",
      "Epoch:6 Loss:0.1290411353111267 iter:2800\n",
      "EVALUATION\n",
      "Epoch:6 Loss:0.05314435064792633 acc:0.99\n",
      "##########################################################################\n",
      "Epoch:7 Loss:0.003531932830810547 iter:0\n",
      "Epoch:7 Loss:0.1422645002603531 iter:400\n",
      "Epoch:7 Loss:0.058745648711919785 iter:800\n",
      "Epoch:7 Loss:0.12497825175523758 iter:1200\n",
      "Epoch:7 Loss:0.08848109096288681 iter:1600\n",
      "Epoch:7 Loss:0.14101839065551758 iter:2000\n",
      "Epoch:7 Loss:0.0824546217918396 iter:2400\n",
      "Epoch:7 Loss:0.08666106313467026 iter:2800\n",
      "EVALUATION\n",
      "Epoch:7 Loss:0.04113110527396202 acc:0.9925\n",
      "##########################################################################\n",
      "Epoch:8 Loss:0.02498459815979004 iter:0\n",
      "Epoch:8 Loss:0.09906313568353653 iter:400\n",
      "Epoch:8 Loss:0.10888095945119858 iter:800\n",
      "Epoch:8 Loss:0.1050424724817276 iter:1200\n",
      "Epoch:8 Loss:0.07674543559551239 iter:1600\n",
      "Epoch:8 Loss:0.0602865070104599 iter:2000\n",
      "Epoch:8 Loss:0.1137775406241417 iter:2400\n",
      "Epoch:8 Loss:0.08010538667440414 iter:2800\n",
      "EVALUATION\n",
      "Epoch:8 Loss:0.03192649036645889 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:9 Loss:0.027935504913330078 iter:0\n",
      "Epoch:9 Loss:0.09531787782907486 iter:400\n",
      "Epoch:9 Loss:0.09165910631418228 iter:800\n",
      "Epoch:9 Loss:0.09713456779718399 iter:1200\n",
      "Epoch:9 Loss:0.0981099084019661 iter:1600\n",
      "Epoch:9 Loss:0.09610449522733688 iter:2000\n",
      "Epoch:9 Loss:0.0890609622001648 iter:2400\n",
      "Epoch:9 Loss:0.08650514483451843 iter:2800\n",
      "EVALUATION\n",
      "Epoch:9 Loss:0.03504866361618042 acc:0.9875\n",
      "##########################################################################\n",
      "Epoch:10 Loss:0.012730598449707031 iter:0\n",
      "Epoch:10 Loss:0.06066785380244255 iter:400\n",
      "Epoch:10 Loss:0.08676615357398987 iter:800\n",
      "Epoch:10 Loss:0.08465598523616791 iter:1200\n",
      "Epoch:10 Loss:0.08634490519762039 iter:1600\n",
      "Epoch:10 Loss:0.06071558967232704 iter:2000\n",
      "Epoch:10 Loss:0.08164474368095398 iter:2400\n",
      "Epoch:10 Loss:0.06921885162591934 iter:2800\n",
      "EVALUATION\n",
      "Epoch:10 Loss:0.022400859743356705 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:11 Loss:0.003260374069213867 iter:0\n",
      "Epoch:11 Loss:0.03955017402768135 iter:400\n",
      "Epoch:11 Loss:0.07339388132095337 iter:800\n",
      "Epoch:11 Loss:0.08629085123538971 iter:1200\n",
      "Epoch:11 Loss:0.06216111406683922 iter:1600\n",
      "Epoch:11 Loss:0.053328994661569595 iter:2000\n",
      "Epoch:11 Loss:0.06255184859037399 iter:2400\n",
      "Epoch:11 Loss:0.042822446674108505 iter:2800\n",
      "EVALUATION\n",
      "Epoch:11 Loss:0.0324551947414875 acc:0.9925\n",
      "##########################################################################\n",
      "Epoch:12 Loss:0.012980937957763672 iter:0\n",
      "Epoch:12 Loss:0.06496088206768036 iter:400\n",
      "Epoch:12 Loss:0.05396183952689171 iter:800\n",
      "Epoch:12 Loss:0.05117747187614441 iter:1200\n",
      "Epoch:12 Loss:0.039704661816358566 iter:1600\n",
      "Epoch:12 Loss:0.08010731637477875 iter:2000\n",
      "Epoch:12 Loss:0.056149594485759735 iter:2400\n",
      "Epoch:12 Loss:0.053598180413246155 iter:2800\n",
      "EVALUATION\n",
      "Epoch:12 Loss:0.023969048634171486 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:13 Loss:0.015345096588134766 iter:0\n",
      "Epoch:13 Loss:0.07090786844491959 iter:400\n",
      "Epoch:13 Loss:0.055120982229709625 iter:800\n",
      "Epoch:13 Loss:0.05194523558020592 iter:1200\n",
      "Epoch:13 Loss:0.053003523498773575 iter:1600\n",
      "Epoch:13 Loss:0.08559799939393997 iter:2000\n",
      "Epoch:13 Loss:0.05241634324193001 iter:2400\n",
      "Epoch:13 Loss:0.05071476846933365 iter:2800\n",
      "EVALUATION\n",
      "Epoch:13 Loss:0.022146670147776604 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:14 Loss:0.0010340213775634766 iter:0\n",
      "Epoch:14 Loss:0.05943974480032921 iter:400\n",
      "Epoch:14 Loss:0.05303976312279701 iter:800\n",
      "Epoch:14 Loss:0.0666203424334526 iter:1200\n",
      "Epoch:14 Loss:0.0402810201048851 iter:1600\n",
      "Epoch:14 Loss:0.06257283687591553 iter:2000\n",
      "Epoch:14 Loss:0.03974267467856407 iter:2400\n",
      "Epoch:14 Loss:0.06569351255893707 iter:2800\n",
      "EVALUATION\n",
      "Epoch:14 Loss:0.021703924983739853 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:15 Loss:0.002390623092651367 iter:0\n",
      "Epoch:15 Loss:0.05109920725226402 iter:400\n",
      "Epoch:15 Loss:0.049217887222766876 iter:800\n",
      "Epoch:15 Loss:0.0451967790722847 iter:1200\n",
      "Epoch:15 Loss:0.050801847130060196 iter:1600\n",
      "Epoch:15 Loss:0.04474986344575882 iter:2000\n",
      "Epoch:15 Loss:0.0546775721013546 iter:2400\n",
      "Epoch:15 Loss:0.07572575658559799 iter:2800\n",
      "EVALUATION\n",
      "Epoch:15 Loss:0.014659645035862923 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:16 Loss:0.010944843292236328 iter:0\n",
      "Epoch:16 Loss:0.06515844166278839 iter:400\n",
      "Epoch:16 Loss:0.0461231991648674 iter:800\n",
      "Epoch:16 Loss:0.0374014787375927 iter:1200\n",
      "Epoch:16 Loss:0.0504349023103714 iter:1600\n",
      "Epoch:16 Loss:0.06622535735368729 iter:2000\n",
      "Epoch:16 Loss:0.058052271604537964 iter:2400\n",
      "Epoch:16 Loss:0.03959834575653076 iter:2800\n",
      "!\n",
      "EVALUATION\n",
      "Epoch:16 Loss:0.00870670098811388 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:17 Loss:0.28359365463256836 iter:0\n",
      "Epoch:17 Loss:0.05738867446780205 iter:400\n",
      "Epoch:17 Loss:0.04799458011984825 iter:800\n",
      "Epoch:17 Loss:0.04766089841723442 iter:1200\n",
      "Epoch:17 Loss:0.03054126910865307 iter:1600\n",
      "Epoch:17 Loss:0.047612451016902924 iter:2000\n",
      "Epoch:17 Loss:0.04481685534119606 iter:2400\n",
      "Epoch:17 Loss:0.030240098014473915 iter:2800\n",
      "EVALUATION\n",
      "Epoch:17 Loss:0.016571009531617165 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:18 Loss:0.011030912399291992 iter:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18 Loss:0.0351397879421711 iter:400\n",
      "Epoch:18 Loss:0.048843372613191605 iter:800\n",
      "Epoch:18 Loss:0.03718214109539986 iter:1200\n",
      "Epoch:18 Loss:0.025898341089487076 iter:1600\n",
      "Epoch:18 Loss:0.03994334861636162 iter:2000\n",
      "Epoch:18 Loss:0.021865949034690857 iter:2400\n",
      "Epoch:18 Loss:0.038187041878700256 iter:2800\n",
      "EVALUATION\n",
      "Epoch:18 Loss:0.01715449057519436 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:19 Loss:0.23639488220214844 iter:0\n",
      "Epoch:19 Loss:0.03324906900525093 iter:400\n",
      "Epoch:19 Loss:0.035276900976896286 iter:800\n",
      "Epoch:19 Loss:0.04554973542690277 iter:1200\n",
      "Epoch:19 Loss:0.029206829145550728 iter:1600\n",
      "Epoch:19 Loss:0.03499673679471016 iter:2000\n",
      "Epoch:19 Loss:0.038566794246435165 iter:2400\n",
      "Epoch:19 Loss:0.02994343638420105 iter:2800\n",
      "EVALUATION\n",
      "Epoch:19 Loss:0.01659964956343174 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:20 Loss:0.002647876739501953 iter:0\n",
      "Epoch:20 Loss:0.04231509566307068 iter:400\n",
      "Epoch:20 Loss:0.03190453350543976 iter:800\n",
      "Epoch:20 Loss:0.03622540459036827 iter:1200\n",
      "Epoch:20 Loss:0.038074247539043427 iter:1600\n",
      "Epoch:20 Loss:0.037099797278642654 iter:2000\n",
      "Epoch:20 Loss:0.040824487805366516 iter:2400\n",
      "Epoch:20 Loss:0.04692571610212326 iter:2800\n",
      "EVALUATION\n",
      "Epoch:20 Loss:0.017348773777484894 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:21 Loss:0.0003001689910888672 iter:0\n",
      "Epoch:21 Loss:0.04570982977747917 iter:400\n",
      "Epoch:21 Loss:0.03731682896614075 iter:800\n",
      "Epoch:21 Loss:0.045428693294525146 iter:1200\n",
      "Epoch:21 Loss:0.04367711395025253 iter:1600\n",
      "Epoch:21 Loss:0.030369063839316368 iter:2000\n",
      "Epoch:21 Loss:0.03572935611009598 iter:2400\n",
      "Epoch:21 Loss:0.040455035865306854 iter:2800\n",
      "EVALUATION\n",
      "Epoch:21 Loss:0.011944164521992207 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:22 Loss:0.0057947635650634766 iter:0\n",
      "Epoch:22 Loss:0.017232878133654594 iter:400\n",
      "Epoch:22 Loss:0.04119240492582321 iter:800\n",
      "Epoch:22 Loss:0.027482595294713974 iter:1200\n",
      "Epoch:22 Loss:0.04031670466065407 iter:1600\n",
      "Epoch:22 Loss:0.02561405673623085 iter:2000\n",
      "Epoch:22 Loss:0.04529093578457832 iter:2400\n",
      "Epoch:22 Loss:0.0342031829059124 iter:2800\n",
      "EVALUATION\n",
      "Epoch:22 Loss:0.011395949870347977 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:23 Loss:0.003842592239379883 iter:0\n",
      "Epoch:23 Loss:0.03096371330320835 iter:400\n",
      "Epoch:23 Loss:0.031010443344712257 iter:800\n",
      "Epoch:23 Loss:0.03410778567194939 iter:1200\n",
      "Epoch:23 Loss:0.03827403485774994 iter:1600\n",
      "Epoch:23 Loss:0.03188963606953621 iter:2000\n",
      "Epoch:23 Loss:0.05087210610508919 iter:2400\n",
      "Epoch:23 Loss:0.05134841427206993 iter:2800\n",
      "EVALUATION\n",
      "Epoch:23 Loss:0.008674826472997665 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:24 Loss:0.00026297569274902344 iter:0\n",
      "Epoch:24 Loss:0.04524380713701248 iter:400\n",
      "Epoch:24 Loss:0.04091715067625046 iter:800\n",
      "Epoch:24 Loss:0.027943752706050873 iter:1200\n",
      "Epoch:24 Loss:0.04998691380023956 iter:1600\n",
      "Epoch:24 Loss:0.029387973248958588 iter:2000\n",
      "Epoch:24 Loss:0.0310126394033432 iter:2400\n",
      "Epoch:24 Loss:0.03682328015565872 iter:2800\n",
      "EVALUATION\n",
      "Epoch:24 Loss:0.020302731543779373 acc:0.9925\n",
      "##########################################################################\n",
      "Epoch:25 Loss:0.0024001598358154297 iter:0\n",
      "Epoch:25 Loss:0.047143466770648956 iter:400\n",
      "Epoch:25 Loss:0.03356849402189255 iter:800\n",
      "Epoch:25 Loss:0.029818283393979073 iter:1200\n",
      "Epoch:25 Loss:0.023854460567235947 iter:1600\n",
      "Epoch:25 Loss:0.037696290761232376 iter:2000\n",
      "Epoch:25 Loss:0.040532540529966354 iter:2400\n",
      "Epoch:25 Loss:0.02782553620636463 iter:2800\n",
      "EVALUATION\n",
      "Epoch:25 Loss:0.01300046220421791 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:26 Loss:0.0033102035522460938 iter:0\n",
      "Epoch:26 Loss:0.02284238673746586 iter:400\n",
      "Epoch:26 Loss:0.020455503836274147 iter:800\n",
      "Epoch:26 Loss:0.04255141317844391 iter:1200\n",
      "Epoch:26 Loss:0.03326454013586044 iter:1600\n",
      "Epoch:26 Loss:0.04404182359576225 iter:2000\n",
      "Epoch:26 Loss:0.02771645411849022 iter:2400\n",
      "Epoch:26 Loss:0.02807815931737423 iter:2800\n",
      "EVALUATION\n",
      "Epoch:26 Loss:0.007992229424417019 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:27 Loss:0.004770755767822266 iter:0\n",
      "Epoch:27 Loss:0.014340292662382126 iter:400\n",
      "Epoch:27 Loss:0.03921631723642349 iter:800\n",
      "Epoch:27 Loss:0.031300947070121765 iter:1200\n",
      "Epoch:27 Loss:0.03304245322942734 iter:1600\n",
      "Epoch:27 Loss:0.020462797954678535 iter:2000\n",
      "Epoch:27 Loss:0.022141799330711365 iter:2400\n",
      "Epoch:27 Loss:0.029994729906320572 iter:2800\n",
      "EVALUATION\n",
      "Epoch:27 Loss:0.01600552350282669 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:28 Loss:0.0016019344329833984 iter:0\n",
      "Epoch:28 Loss:0.026921918615698814 iter:400\n",
      "Epoch:28 Loss:0.01730344071984291 iter:800\n",
      "Epoch:28 Loss:0.01511321309953928 iter:1200\n",
      "Epoch:28 Loss:0.030134299769997597 iter:1600\n",
      "Epoch:28 Loss:0.03700307384133339 iter:2000\n",
      "Epoch:28 Loss:0.030354706570506096 iter:2400\n",
      "Epoch:28 Loss:0.030442658811807632 iter:2800\n",
      "EVALUATION\n",
      "Epoch:28 Loss:0.010869614779949188 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:29 Loss:0.00011777877807617188 iter:0\n",
      "Epoch:29 Loss:0.0316869392991066 iter:400\n",
      "Epoch:29 Loss:0.022992439568042755 iter:800\n",
      "Epoch:29 Loss:0.024360639974474907 iter:1200\n",
      "Epoch:29 Loss:0.020610686391592026 iter:1600\n",
      "Epoch:29 Loss:0.024047700688242912 iter:2000\n",
      "Epoch:29 Loss:0.03354432061314583 iter:2400\n",
      "Epoch:29 Loss:0.033209092915058136 iter:2800\n",
      "EVALUATION\n",
      "Epoch:29 Loss:0.007767548318952322 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:30 Loss:0.00016546249389648438 iter:0\n",
      "Epoch:30 Loss:0.021873587742447853 iter:400\n",
      "Epoch:30 Loss:0.02776883728802204 iter:800\n",
      "Epoch:30 Loss:0.021214332431554794 iter:1200\n",
      "Epoch:30 Loss:0.034096039831638336 iter:1600\n",
      "Epoch:30 Loss:0.022480430081486702 iter:2000\n",
      "Epoch:30 Loss:0.026315851137042046 iter:2400\n",
      "Epoch:30 Loss:0.03546885401010513 iter:2800\n",
      "EVALUATION\n",
      "Epoch:30 Loss:0.0183889027684927 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:31 Loss:0.009938478469848633 iter:0\n",
      "Epoch:31 Loss:0.06033002585172653 iter:400\n",
      "Epoch:31 Loss:0.03691771253943443 iter:800\n",
      "Epoch:31 Loss:0.029508713632822037 iter:1200\n",
      "Epoch:31 Loss:0.03181600570678711 iter:1600\n",
      "Epoch:31 Loss:0.039450302720069885 iter:2000\n",
      "Epoch:31 Loss:0.03510981425642967 iter:2400\n",
      "Epoch:31 Loss:0.033097948879003525 iter:2800\n",
      "EVALUATION\n",
      "Epoch:31 Loss:0.009288289584219456 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:32 Loss:0.00013899803161621094 iter:0\n",
      "Epoch:32 Loss:0.016813987866044044 iter:400\n",
      "Epoch:32 Loss:0.019632186740636826 iter:800\n",
      "Epoch:32 Loss:0.028794914484024048 iter:1200\n",
      "Epoch:32 Loss:0.019678596407175064 iter:1600\n",
      "Epoch:32 Loss:0.024593571200966835 iter:2000\n",
      "Epoch:32 Loss:0.023619940504431725 iter:2400\n",
      "Epoch:32 Loss:0.039413247257471085 iter:2800\n",
      "EVALUATION\n",
      "Epoch:32 Loss:0.006326205562800169 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:33 Loss:0.20879650115966797 iter:0\n",
      "Epoch:33 Loss:0.027068134397268295 iter:400\n",
      "Epoch:33 Loss:0.028283976018428802 iter:800\n",
      "Epoch:33 Loss:0.027289804071187973 iter:1200\n",
      "Epoch:33 Loss:0.03655790537595749 iter:1600\n",
      "Epoch:33 Loss:0.018244720995426178 iter:2000\n",
      "Epoch:33 Loss:0.019926030188798904 iter:2400\n",
      "Epoch:33 Loss:0.022864097729325294 iter:2800\n",
      "EVALUATION\n",
      "Epoch:33 Loss:0.013503667898476124 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:34 Loss:0.242872953414917 iter:0\n",
      "Epoch:34 Loss:0.02678384631872177 iter:400\n",
      "Epoch:34 Loss:0.03201867640018463 iter:800\n",
      "Epoch:34 Loss:0.02917456068098545 iter:1200\n",
      "Epoch:34 Loss:0.03293449804186821 iter:1600\n",
      "Epoch:34 Loss:0.021518966183066368 iter:2000\n",
      "Epoch:34 Loss:0.025492161512374878 iter:2400\n",
      "Epoch:34 Loss:0.020053964108228683 iter:2800\n",
      "EVALUATION\n",
      "Epoch:34 Loss:0.0060505676083266735 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:35 Loss:0.00018668174743652344 iter:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35 Loss:0.028156591579318047 iter:400\n",
      "Epoch:35 Loss:0.01650088094174862 iter:800\n",
      "Epoch:35 Loss:0.03002168983221054 iter:1200\n",
      "Epoch:35 Loss:0.016120582818984985 iter:1600\n",
      "Epoch:35 Loss:0.014049186371266842 iter:2000\n",
      "Epoch:35 Loss:0.015317440032958984 iter:2400\n",
      "Epoch:35 Loss:0.027850951999425888 iter:2800\n",
      "EVALUATION\n",
      "Epoch:35 Loss:0.012398185208439827 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:36 Loss:0.0002503395080566406 iter:0\n",
      "Epoch:36 Loss:0.04084049165248871 iter:400\n",
      "Epoch:36 Loss:0.018076743930578232 iter:800\n",
      "Epoch:36 Loss:0.02652854472398758 iter:1200\n",
      "Epoch:36 Loss:0.0220942422747612 iter:1600\n",
      "Epoch:36 Loss:0.02446967363357544 iter:2000\n",
      "Epoch:36 Loss:0.038156960159540176 iter:2400\n",
      "Epoch:36 Loss:0.026872029528021812 iter:2800\n",
      "EVALUATION\n",
      "Epoch:36 Loss:0.006831629201769829 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:37 Loss:0.0015168190002441406 iter:0\n",
      "Epoch:37 Loss:0.022399842739105225 iter:400\n",
      "Epoch:37 Loss:0.025187598541378975 iter:800\n",
      "Epoch:37 Loss:0.01968805305659771 iter:1200\n",
      "Epoch:37 Loss:0.02291424386203289 iter:1600\n",
      "Epoch:37 Loss:0.020898859947919846 iter:2000\n",
      "Epoch:37 Loss:0.011507060378789902 iter:2400\n",
      "Epoch:37 Loss:0.033612657338380814 iter:2800\n",
      "EVALUATION\n",
      "Epoch:37 Loss:0.007098943926393986 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:38 Loss:0.00011968612670898438 iter:0\n",
      "Epoch:38 Loss:0.012711879797279835 iter:400\n",
      "Epoch:38 Loss:0.016410989686846733 iter:800\n",
      "Epoch:38 Loss:0.03021269291639328 iter:1200\n",
      "Epoch:38 Loss:0.02020435966551304 iter:1600\n",
      "Epoch:38 Loss:0.020306894555687904 iter:2000\n",
      "Epoch:38 Loss:0.02215791493654251 iter:2400\n",
      "Epoch:38 Loss:0.01631370186805725 iter:2800\n",
      "EVALUATION\n",
      "Epoch:38 Loss:0.00619801040738821 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:39 Loss:0.0011348724365234375 iter:0\n",
      "Epoch:39 Loss:0.017535297200083733 iter:400\n",
      "Epoch:39 Loss:0.015156030654907227 iter:800\n",
      "Epoch:39 Loss:0.009031221270561218 iter:1200\n",
      "Epoch:39 Loss:0.018538130447268486 iter:1600\n",
      "Epoch:39 Loss:0.01880554109811783 iter:2000\n",
      "Epoch:39 Loss:0.02941315993666649 iter:2400\n",
      "Epoch:39 Loss:0.028825577348470688 iter:2800\n",
      "EVALUATION\n",
      "Epoch:39 Loss:0.008314146660268307 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:40 Loss:0.001611948013305664 iter:0\n",
      "Epoch:40 Loss:0.021128730848431587 iter:400\n",
      "Epoch:40 Loss:0.014405779540538788 iter:800\n",
      "Epoch:40 Loss:0.021675292402505875 iter:1200\n",
      "Epoch:40 Loss:0.021158067509531975 iter:1600\n",
      "Epoch:40 Loss:0.015125727280974388 iter:2000\n",
      "Epoch:40 Loss:0.022961163893342018 iter:2400\n",
      "Epoch:40 Loss:0.015117732807993889 iter:2800\n",
      "EVALUATION\n",
      "Epoch:40 Loss:0.007690539117902517 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:41 Loss:0.000141143798828125 iter:0\n",
      "Epoch:41 Loss:0.01980382576584816 iter:400\n",
      "Epoch:41 Loss:0.022938601672649384 iter:800\n",
      "Epoch:41 Loss:0.02204912342131138 iter:1200\n",
      "Epoch:41 Loss:0.014804380014538765 iter:1600\n",
      "Epoch:41 Loss:0.02020379714667797 iter:2000\n",
      "Epoch:41 Loss:0.021742429584264755 iter:2400\n",
      "Epoch:41 Loss:0.026335647329688072 iter:2800\n",
      "EVALUATION\n",
      "Epoch:41 Loss:0.00586868729442358 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:42 Loss:8.153915405273438e-05 iter:0\n",
      "Epoch:42 Loss:0.021207204088568687 iter:400\n",
      "Epoch:42 Loss:0.026176167652010918 iter:800\n",
      "Epoch:42 Loss:0.013200636021792889 iter:1200\n",
      "Epoch:42 Loss:0.01742888242006302 iter:1600\n",
      "Epoch:42 Loss:0.016999265179038048 iter:2000\n",
      "Epoch:42 Loss:0.02535305730998516 iter:2400\n",
      "Epoch:42 Loss:0.014833459630608559 iter:2800\n",
      "EVALUATION\n",
      "Epoch:42 Loss:0.007205483969300985 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:43 Loss:0.0018491744995117188 iter:0\n",
      "Epoch:43 Loss:0.020223015919327736 iter:400\n",
      "Epoch:43 Loss:0.012511453591287136 iter:800\n",
      "Epoch:43 Loss:0.012101494707167149 iter:1200\n",
      "Epoch:43 Loss:0.017238164320588112 iter:1600\n",
      "Epoch:43 Loss:0.021291691809892654 iter:2000\n",
      "Epoch:43 Loss:0.02144026942551136 iter:2400\n",
      "Epoch:43 Loss:0.0167690496891737 iter:2800\n",
      "EVALUATION\n",
      "Epoch:43 Loss:0.009204313158988953 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:44 Loss:0.0022640228271484375 iter:0\n",
      "Epoch:44 Loss:0.016613611951470375 iter:400\n",
      "Epoch:44 Loss:0.03149533271789551 iter:800\n",
      "Epoch:44 Loss:0.024172086268663406 iter:1200\n",
      "Epoch:44 Loss:0.021370001137256622 iter:1600\n",
      "Epoch:44 Loss:0.011976799927651882 iter:2000\n",
      "Epoch:44 Loss:0.00818087998777628 iter:2400\n",
      "Epoch:44 Loss:0.015047967433929443 iter:2800\n",
      "EVALUATION\n",
      "Epoch:44 Loss:0.006883916910737753 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:45 Loss:0.12991976737976074 iter:0\n",
      "Epoch:45 Loss:0.015542411245405674 iter:400\n",
      "Epoch:45 Loss:0.020198535174131393 iter:800\n",
      "Epoch:45 Loss:0.01569400355219841 iter:1200\n",
      "Epoch:45 Loss:0.024755708873271942 iter:1600\n",
      "Epoch:45 Loss:0.019616272300481796 iter:2000\n",
      "Epoch:45 Loss:0.018705321475863457 iter:2400\n",
      "Epoch:45 Loss:0.02773340418934822 iter:2800\n",
      "EVALUATION\n",
      "Epoch:45 Loss:0.007438688073307276 acc:0.9975\n",
      "##########################################################################\n",
      "Epoch:46 Loss:0.0014672279357910156 iter:0\n",
      "Epoch:46 Loss:0.020276959985494614 iter:400\n",
      "Epoch:46 Loss:0.0178932286798954 iter:800\n",
      "Epoch:46 Loss:0.02217797003686428 iter:1200\n",
      "Epoch:46 Loss:0.0103200264275074 iter:1600\n",
      "Epoch:46 Loss:0.018367085605859756 iter:2000\n",
      "Epoch:46 Loss:0.02294998988509178 iter:2400\n",
      "Epoch:46 Loss:0.012706744484603405 iter:2800\n",
      "EVALUATION\n",
      "Epoch:46 Loss:0.00731347780674696 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:47 Loss:0.0006842613220214844 iter:0\n",
      "Epoch:47 Loss:0.020475607365369797 iter:400\n",
      "Epoch:47 Loss:0.011986193247139454 iter:800\n",
      "Epoch:47 Loss:0.01664799451828003 iter:1200\n",
      "Epoch:47 Loss:0.018225183710455894 iter:1600\n",
      "Epoch:47 Loss:0.021910687908530235 iter:2000\n",
      "Epoch:47 Loss:0.020816318690776825 iter:2400\n",
      "Epoch:47 Loss:0.013025803491473198 iter:2800\n",
      "EVALUATION\n",
      "Epoch:47 Loss:0.00643253093585372 acc:1.0\n",
      "##########################################################################\n",
      "Epoch:48 Loss:0.12471938133239746 iter:0\n",
      "Epoch:48 Loss:0.01480195950716734 iter:400\n",
      "Epoch:48 Loss:0.019046064466238022 iter:800\n",
      "Epoch:48 Loss:0.016661953181028366 iter:1200\n",
      "Epoch:48 Loss:0.021222278475761414 iter:1600\n",
      "Epoch:48 Loss:0.01463390327990055 iter:2000\n",
      "Epoch:48 Loss:0.012541431933641434 iter:2400\n",
      "Epoch:48 Loss:0.018940798938274384 iter:2800\n",
      "EVALUATION\n",
      "Epoch:48 Loss:0.007988367229700089 acc:0.995\n",
      "##########################################################################\n",
      "Epoch:49 Loss:0.0011212825775146484 iter:0\n",
      "Epoch:49 Loss:0.0159057155251503 iter:400\n",
      "Epoch:49 Loss:0.016030678525567055 iter:800\n",
      "Epoch:49 Loss:0.014724358916282654 iter:1200\n",
      "Epoch:49 Loss:0.015237933956086636 iter:1600\n",
      "Epoch:49 Loss:0.014634286984801292 iter:2000\n",
      "Epoch:49 Loss:0.017117440700531006 iter:2400\n",
      "Epoch:49 Loss:0.020593678578734398 iter:2800\n",
      "EVALUATION\n",
      "Epoch:49 Loss:0.00805246364325285 acc:0.9975\n",
      "##########################################################################\n"
     ]
    }
   ],
   "source": [
    "acc_max = 0\n",
    "for epoch in range(epoch_max):\n",
    "    loss_epoch = 0\n",
    "    loss_count = 0\n",
    "    net.train()\n",
    "    for i, ((img1,img2),label) in enumerate(trainloader):\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        label = torch.tensor(label,dtype=torch.int64).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = net(img1,img2)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        if i*batchsize%400 == 0:\n",
    "            print(\"Epoch:{} Loss:{} iter:{}\".format(epoch, loss_epoch/loss_count, i*batchsize))\n",
    "            loss_epoch = 0\n",
    "            loss_count = 0\n",
    "            \n",
    "    \n",
    "            \n",
    "    loss_epoch = 0\n",
    "    loss_count = 0\n",
    "    predict = []\n",
    "    expect = []\n",
    "    net.eval()\n",
    "    for i, ((img1,img2),label) in enumerate(validloader):\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        label = torch.tensor(label,dtype=torch.int64).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = net(img1,img2)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss_epoch += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        predict.append(np.argmax(output.cpu().numpy()))\n",
    "        expect.append(label.cpu().numpy().item())\n",
    "    acc = accuracy_score(expect, predict)\n",
    "    \n",
    "    if acc_max < acc:\n",
    "        print(\"!\")\n",
    "        acc_max = acc\n",
    "        best_model_wts = copy.deepcopy(net.state_dict())\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    print(\"EVALUATION\\nEpoch:{} Loss:{} acc:{}\".format(epoch, loss_epoch/loss_count, acc))\n",
    "    print(\"##########################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_wts,\"twostream_Epoch{}_validAcc{}\".format(best_epoch,acc_max))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
