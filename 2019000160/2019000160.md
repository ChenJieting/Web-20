# Few-Shot Learning on Self-Collected Dataset of Birds
费楠益 (Nanyi Fei, 2019000160)

## Abstract
Few-shot learning (FSL) aims to learn a model that is able to quickly adapt to novel classes with only a few labeled samples. Most recent FSL approaches are based on meta-learning, which exploits episodic training for model optimization. In this project, I attempt to address a fundamental issue in FSL, i.e., a classifier built upon as few as one shot per class is inevitably sensitive to the sampling of the few shots. To this end, a novel alignment regularization is proposed which enforces classifier prediction consistency between the sampled support set and the augmented support set. Such a consistency regularization typically requires no class labels, which has been widely used in self- and semi-supervised learning. The resultant unsupervised alignment/consistency loss thus intrinsically makes existing meta-learning based FSL mdoels (e.g., Prototypical Network (ProtoNet)) robust against badly sampled shots that give little chance to build a good classifier. Experiments on the self-collected dataset of birds demonstrate that my alignment loss can boost ProtoNet by a significant margin.

## Environment
* Python 3.7.6
* PyTorch 1.5.0

## Get Started
### Preparations
1. Folder '/src/dataset' should contain the raw images of the [self-collected dataset of birds](https://pan.baidu.com/s/1Hwm0NK2jdOb_r2cT2YPwig) (enter code: vquf) and three '.csv' files.
  
2. The pretrained WRN on the [Places365 dataset](https://github.com/CSAILVision/places365) is used for the experiments. Folder '/src/scripts/pretrain' should include the [pretrained WRN model](https://pan.baidu.com/s/1Jr-9Vch6_OngP2fzrpgkEA) (enter code: 5kqh, 140.5M).

3. Create two folders for experiment results: '/src/scripts/exp_5shot' and '/src/scripts/exp_1shot'.

### Model Training and Test
1. Train ProtoNet under the 5-way 5-shot setting.
    -- python train.py --output_dir ./exp_5shot/proto_exp1 --shot 5 --init_lr 0.001 --lambda_align 0
2. Evaluate ProtoNet under the 5-way 5-shot setting.
    -- python test.py --output_dir ./exp_5shot/proto_exp1 --load ./exp_5shot/proto_exp1/best_model.pth.tar --shot 5
3. Train ProtoNet under the 5-way 1-shot setting.
    -- python train.py --output_dir ./exp_1shot/proto_exp1 --shot 1 --init_lr 0.0001 --lambda_align 0
4. Evaluate ProtoNet under the 5-way 1-shot setting.
    -- python test.py --output_dir ./exp_1shot/proto_exp1 --load ./exp_1shot/proto_exp1/best_model.pth.tar --shot 1
5. Train ProtoNet+Align under the 5-way 5-shot setting.
    -- python train.py --output_dir ./exp_5shot/align_exp1 --shot 5 --init_lr 0.001 --lambda_align 1 --T 16
6. Evaluate ProtoNet+Align under the 5-way 5-shot setting.
    -- python test.py --output_dir ./exp_5shot/align_exp1 --load ./exp_5shot/align_exp1/best_model.pth.tar --shot 5
7. Train ProtoNet+Align under the 5-way 1-shot setting.
    -- python train.py --output_dir ./exp_1shot/align_exp1 --shot 1 --init_lr 0.0001 --lambda_align 1 --T 16
8. Evaluate ProtoNet+Align under the 5-way 1-shot setting.
    -- python test.py --output_dir ./exp_1shot/align_exp1 --load ./exp_1shot/align_exp1/best_model.pth.tar --shot 1

Please don't forget to check other arguments before running the code.

## Acknowledgment
Thank following repos for providing helpful components/functions in this project.
1. Prototypical Networks for Few-shot Learning https://github.com/cyvius96/prototypical-network-pytorch
2. A Closer Look at Few-shot Classification https://github.com/wyharveychen/CloserLookFewShot
